{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Models Processing",
   "id": "d6e2cedd02b6939d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T20:03:27.250576Z",
     "start_time": "2025-01-12T20:03:27.246169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_paths = {\n",
    "        'model1': \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "        'model2': \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "        'model3': \"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "        'model4': \"siebert/sentiment-roberta-large-english\",\n",
    "        'model5': \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
    "        'model6': \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
    "        'model7': \"j-hartmann/sentiment-roberta-large-english-3-classes\"\n",
    "}"
   ],
   "id": "386ff004e650c4db",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T20:03:33.640317Z",
     "start_time": "2025-01-12T20:03:28.201449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models = {name : pipeline('sentiment-analysis', model=model_path) for name, model_path in model_paths.items()}"
   ],
   "id": "454c5cb0b00cfc3c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Some weights of the model checkpoint at j-hartmann/sentiment-roberta-large-english-3-classes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Text Importing",
   "id": "5b1210adce8888b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T20:03:41.570342Z",
     "start_time": "2025-01-12T20:03:41.361578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('posts_first_targil.xlsx', sheet_name=None)"
   ],
   "id": "8836857cc7fc59e8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T20:03:42.627306Z",
     "start_time": "2025-01-12T20:03:42.622321Z"
    }
   },
   "cell_type": "code",
   "source": "df['J-P'].rename(columns={'Body': 'Body Text'}, inplace=True)",
   "id": "e82bc4d16585cf01",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T20:03:43.592762Z",
     "start_time": "2025-01-12T20:03:43.587340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for sheet_name, sheet_df in df.items():\n",
    "    print(f\"Sheet name: {sheet_name}\")\n",
    "    print(sheet_df.columns)"
   ],
   "id": "d25ec06053e544b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet name: A-J\n",
      "Index(['sub_title', 'date', 'Newspaper', 'Body Text', 'title'], dtype='object')\n",
      "Sheet name: BBC\n",
      "Index(['date', 'Newspaper', 'Body Text', 'title'], dtype='object')\n",
      "Sheet name: J-P\n",
      "Index(['date', 'Newspaper', 'Body Text', 'title'], dtype='object')\n",
      "Sheet name: NY-T\n",
      "Index(['date', 'Newspaper', 'Body Text', 'title'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T20:03:45.113153Z",
     "start_time": "2025-01-12T20:03:45.109627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('israel.txt', 'r') as israel_file, open('palestine.txt', 'r') as palestine_file:\n",
    "    i_word = israel_file.read().splitlines()\n",
    "    p_word = palestine_file.read().splitlines()\n"
   ],
   "id": "aa3f6141bf4d0eae",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T20:03:46.261786Z",
     "start_time": "2025-01-12T20:03:46.258766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i_word = [word.lower() for word in i_word]\n",
    "p_word = [word.lower() for word in p_word]"
   ],
   "id": "997fa254a0d1275e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T20:03:46.959743Z",
     "start_time": "2025-01-12T20:03:46.954756Z"
    }
   },
   "cell_type": "code",
   "source": "i_word",
   "id": "9591e3329d67da2d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zionism',\n",
       " 'homeland',\n",
       " 'security',\n",
       " 'independence',\n",
       " 'jerusalem',\n",
       " 'idf',\n",
       " 'peace',\n",
       " 'democracy',\n",
       " 'resilience',\n",
       " 'nationhood',\n",
       " 'unity',\n",
       " 'innovation',\n",
       " 'strength',\n",
       " 'sovereignty',\n",
       " 'hope',\n",
       " 'freedom',\n",
       " 'patriotism',\n",
       " 'courage',\n",
       " 'shield',\n",
       " 'jerusalem',\n",
       " 'jewish',\n",
       " 'defense',\n",
       " 'victorious',\n",
       " 'innovation',\n",
       " 'heritage',\n",
       " 'stability',\n",
       " 'pride',\n",
       " 'prosperity',\n",
       " 'protection',\n",
       " 'self-defense']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T20:03:49.025993Z",
     "start_time": "2025-01-12T20:03:48.456873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "csv1 = []\n",
    "\n",
    "for sheet_name, sheet_df in df.items():\n",
    "    for index, row in sheet_df.iterrows():\n",
    "\n",
    "        article_sentences = []\n",
    "\n",
    "        if pd.notna(row['Body Text']):\n",
    "            article_sentences += row['Body Text'].lower().split('.')\n",
    "\n",
    "        if pd.notna(row['title']):\n",
    "            article_sentences += row['title'].lower().split('.')\n",
    "\n",
    "        if sheet_name == 'A-J' and pd.notna(row['sub_title']):\n",
    "            article_sentences += row['sub_title'].lower().split('.')\n",
    "\n",
    "        for sentence in article_sentences:\n",
    "            if any(word in sentence for word in i_word) and not any(word in sentence for word in p_word):\n",
    "                csv1.append({'paper': sheet_name, 'article_index': index, 'sentence': sentence, 'I/P': 'I'})\n",
    "            elif any(word in sentence for word in p_word) and not any(word in sentence for word in i_word):\n",
    "                csv1.append({'paper': sheet_name, 'article_index': index, 'sentence': sentence, 'I/P': 'P'})"
   ],
   "id": "6bf50561a27ac017",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-12T20:09:51.049463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Label normalization\n",
    "positive_labels = ['POSITIVE', 'positive', '4 stars', '5 stars', 'POS']\n",
    "negative_labels = ['NEGATIVE', 'negative', '1 star', '2 stars', 'NEG']\n",
    "\n",
    "def normalize_label(label):\n",
    "    if label in positive_labels:\n",
    "        return 'POS'\n",
    "    elif label in negative_labels:\n",
    "        return 'NEG'\n",
    "    else:\n",
    "        return 'NUT'\n",
    "\n",
    "# Chunk splitting\n",
    "def split_into_chunks(sentence, chunk_size=128):\n",
    "    words = sentence.split(' ')\n",
    "    chunks = []\n",
    "\n",
    "    while len(words) > chunk_size:\n",
    "        chunks.append(' '.join(words[:chunk_size]))\n",
    "        words = words[chunk_size:]\n",
    "\n",
    "    chunks.append(' '.join(words))\n",
    "    return chunks\n",
    "\n",
    "# Determine majority label\n",
    "def determine_majority_label(label_counts):\n",
    "    return 'POS' if label_counts['POS'] > label_counts['NEG'] and label_counts['POS'] > label_counts['NUT'] else 'NEG' if label_counts['NEG'] > label_counts['POS'] and label_counts['NEG'] > label_counts['NUT'] else 'NUT' if label_counts['NUT'] > label_counts['POS'] and label_counts['NUT'] > label_counts['NEG'] else 'N/A'\n",
    "\n",
    "# Process model results\n",
    "def process_model_results(results):\n",
    "    label_counts = {'POS': 0, 'NEG': 0, 'NUT': 0}\n",
    "    score_sums = {'POS': 0, 'NEG': 0, 'NUT': 0}\n",
    "\n",
    "    for result in results:\n",
    "        label = normalize_label(result['label'])\n",
    "        score = result['score']\n",
    "\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "            score_sums[label] += score\n",
    "\n",
    "    majority_label = determine_majority_label(label_counts)\n",
    "    average_score = score_sums[majority_label] / label_counts[majority_label] if majority_label != 'N/A' else 1\n",
    "\n",
    "    return {\n",
    "        'label': majority_label,\n",
    "        'score': average_score,\n",
    "    }\n",
    "\n",
    "# Process a single sentence\n",
    "def process_sentence(sentence, models):\n",
    "    pos, neg, nut = 0, 0, 0\n",
    "    sum_pos, sum_neg, sum_nut = 0, 0, 0\n",
    "\n",
    "    split_sentence = split_into_chunks(sentence['sentence'])\n",
    "\n",
    "\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        processed_results = model(sentence['sentence'], truncation=True, max_length=128)[0] if model_name == 'model6' else model(sentence['sentence'])[0]\n",
    "        # processed_results = process_model_results(model_results)\n",
    "\n",
    "        sentence[f'{model_name} score'] = processed_results['score']\n",
    "        sentence[f'{model_name} label'] = processed_results['label']\n",
    "\n",
    "        # Aggregate counts and scores\n",
    "        pos = pos + 1 if processed_results['label'] == 'POS' else pos\n",
    "        neg = neg + 1 if processed_results['label'] == 'NEG' else neg\n",
    "        nut = nut + 1 if processed_results['label'] == 'NUT' else nut\n",
    "\n",
    "        sum_pos = sum_pos + processed_results['score'] if processed_results['label'] == 'POS' else sum_pos\n",
    "        sum_neg = sum_neg + processed_results['score'] if processed_results['label'] == 'NEG' else sum_neg\n",
    "        sum_nut = sum_nut + processed_results['score'] if processed_results['label'] == 'NUT' else sum_nut\n",
    "\n",
    "    label_counts = {'POS': pos, 'NEG': neg, 'NUT': nut}\n",
    "    score_sums = {'POS': sum_pos, 'NEG': sum_neg, 'NUT': sum_nut}\n",
    "\n",
    "    sentence['majority'] = determine_majority_label(label_counts)\n",
    "    sentence['AVG-majority-score'] = score_sums[sentence['majority']] / label_counts[sentence['majority']] if sentence['majority'] != 'N/A' else 'N/A'\n",
    "\n",
    "# Process the CSV data\n",
    "def process_csv(csv_data, models):\n",
    "    for sentence in tqdm(csv_data, colour='green'):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            process_sentence(sentence, models)\n",
    "\n",
    "process_csv(csv1, models)"
   ],
   "id": "827f47d779fa7ec6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001B[32m          \u001B[0m| 6/8368 [00:02<59:56,  2.33it/s]  "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_csv1 = pd.DataFrame(csv1)\n",
    "df_csv1.to_csv('csv1.csv', index=False)"
   ],
   "id": "87a7ccb27189654a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Label normalization\n",
    "positive_labels = ['POSITIVE', 'positive', '4 stars', '5 stars', 'POS']\n",
    "negative_labels = ['NEGATIVE', 'negative', '1 star', '2 stars', 'NEG']\n",
    "\n",
    "def normalize_label(label):\n",
    "    if label in positive_labels:\n",
    "        return 'POS'\n",
    "    elif label in negative_labels:\n",
    "        return 'NEG'\n",
    "    else:\n",
    "        return 'NUT'\n",
    "\n",
    "# Chunk splitting\n",
    "def split_into_chunks(sentence, chunk_size=128):\n",
    "    words = sentence.split(' ')\n",
    "    chunks = []\n",
    "\n",
    "    while len(words) > chunk_size:\n",
    "        chunks.append(' '.join(words[:chunk_size]))\n",
    "        words = words[chunk_size:]\n",
    "\n",
    "    chunks.append(' '.join(words))\n",
    "    return chunks\n",
    "\n",
    "# Determine majority label\n",
    "def determine_majority_label(label_counts):\n",
    "    return 'POS' if label_counts['POS'] >= 4 else 'NEG' if label_counts['NEG'] >= 4 else 'NUT' if label_counts['NUT'] >= 4 else 'N/A'\n",
    "\n",
    "# Process model results\n",
    "def process_model_results(results):\n",
    "    label_counts = {'POS': 0, 'NEG': 0, 'NUT': 0}\n",
    "    score_sums = {'POS': 0, 'NEG': 0, 'NUT': 0}\n",
    "\n",
    "    for result in results:\n",
    "        label = normalize_label(result['label'])\n",
    "        score = result['score']\n",
    "\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "            score_sums[label] += score\n",
    "\n",
    "    majority_label = determine_majority_label(label_counts)\n",
    "    average_score = score_sums[majority_label] / label_counts[majority_label] if majority_label != 'N/A' else 1\n",
    "\n",
    "    return {\n",
    "        'label': majority_label,\n",
    "        'score': average_score,\n",
    "    }\n",
    "\n",
    "# Process a single sentence\n",
    "def process_sentence(sentence, models):\n",
    "    pos, neg, nut = 0, 0, 0\n",
    "    sum_pos, sum_neg, sum_nut = 0, 0, 0\n",
    "\n",
    "    split_sentence = split_into_chunks(sentence['sentence'])\n",
    "\n",
    "\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        processed_results = model(sentence['sentence'], truncation=True, max_length=128)[0] if model_name == 'model6' else model(sentence['sentence'])[0]\n",
    "        # processed_results = process_model_results(model_results)\n",
    "\n",
    "        sentence[f'{model_name} score'] = processed_results['score']\n",
    "        sentence[f'{model_name} label'] = processed_results['label']\n",
    "\n",
    "        # Aggregate counts and scores\n",
    "        pos = pos + 1 if processed_results['label'] == 'POS' else pos\n",
    "        neg = neg + 1 if processed_results['label'] == 'NEG' else neg\n",
    "        nut = nut + 1 if processed_results['label'] == 'NUT' else nut\n",
    "\n",
    "        sum_pos = sum_pos + processed_results['score'] if processed_results['label'] == 'POS' else sum_pos\n",
    "        sum_neg = sum_neg + processed_results['score'] if processed_results['label'] == 'NEG' else sum_neg\n",
    "        sum_nut = sum_nut + processed_results['score'] if processed_results['label'] == 'NUT' else sum_nut\n",
    "\n",
    "    label_counts = {'POS': pos, 'NEG': neg, 'NUT': nut}\n",
    "    score_sums = {'POS': sum_pos, 'NEG': sum_neg, 'NUT': sum_nut}\n",
    "\n",
    "    sentence['majority'] = determine_majority_label(label_counts)\n",
    "    sentence['AVG-majority-score'] = score_sums[sentence['majority']] / label_counts[sentence['majority']] if sentence['majority'] != 'N/A' else 'N/A'\n",
    "\n",
    "# Process the CSV data\n",
    "def process_csv(csv_data, models):\n",
    "    for sentence in tqdm(csv_data, colour='green'):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            process_sentence(sentence, models)\n",
    "\n",
    "process_csv(csv1, models)"
   ],
   "id": "9c2f352a6f454c37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_csv2 = pd.DataFrame(csv1)\n",
    "df_csv2.to_csv('csv2.csv', index=False)"
   ],
   "id": "bb6094ceb30632c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_highest_label(label_counts):\n",
    "\n",
    "    # Find the maximum value in the dictionary\n",
    "    max_value = max(label_counts.values())\n",
    "\n",
    "    # Find all keys with the maximum value\n",
    "    highest_labels = [key for key, value in label_counts.items() if value == max_value]\n",
    "\n",
    "    # Return the label if there is only one; otherwise, return 'N/A' for ties\n",
    "    return highest_labels[0] if len(highest_labels) == 1 else 'N/A'"
   ],
   "id": "a897c2c2083236f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "papers_df = []\n",
    "for paper in df_csv1['paper'].unique():\n",
    "    paper_df = df_csv1[df_csv1['paper'] == paper]\n",
    "\n",
    "    articles = []\n",
    "\n",
    "    for article_index in paper_df['article_index'].unique():\n",
    "\n",
    "        article_df = df_csv1[df_csv1['article_index'] == article_index]\n",
    "        label_counts = {'POS-I': 0, 'POS-P': 0, 'NUT': 0}\n",
    "        score_sums = {'POS-I': 0, 'POS-P': 0, 'NUT': 0}\n",
    "\n",
    "        for index, row in article_df.iterrows():\n",
    "\n",
    "            if (row['majority'] == 'POS' and row['I/P'] == 'I') or (row['majority'] == 'NEG' and row['I/P'] == 'P'):\n",
    "                label_counts['POS-I'] += 1\n",
    "                score_sums['POS-I'] += row['AVG-majority-score']\n",
    "            elif (row['majority'] == 'POS' and row['I/P'] == 'P') or (row['majority'] == 'NEG' and row['I/P'] == 'I'):\n",
    "                label_counts['POS-P'] += 1\n",
    "                score_sums['POS-P'] += row['AVG-majority-score']\n",
    "            elif row['majority'] == 'NUT':\n",
    "                label_counts['NUT'] += 1\n",
    "                score_sums['NUT'] += row['AVG-majority-score']\n",
    "\n",
    "        majority_label = get_highest_label(label_counts)\n",
    "        articles.append({\n",
    "            'article_index': article_index,\n",
    "            'majority': majority_label,\n",
    "            'score': score_sums[majority_label] / label_counts[majority_label] if majority_label != 'N/A' else 1,\n",
    "        })\n",
    "\n",
    "    papers_df.append((pd.DataFrame(articles), paper))"
   ],
   "id": "6b7c12d5ec63738a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with pd.ExcelWriter('excel2.xlsx') as writer:\n",
    "    for df, sheet_name in papers_df:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ],
   "id": "1daf5d11adbec9bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for df, sheet_name in papers_df:\n",
    "    pro_classification = df['majority'].value_counts()\n",
    "    pro_classification = pro_classification.to_dict()\n",
    "    pro_classification['N/A'] = 0\n",
    "\n",
    "    decided_pro = get_highest_label(pro_classification)\n",
    "    score = df[df['majority'] == decided_pro]['score'].mean() if decided_pro != 'N/A' else 'N/A'\n",
    "    print(f'paper: {sheet_name} label: {decided_pro} score: {score}')"
   ],
   "id": "263ea05e303bfa0e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
